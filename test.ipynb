{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np \n",
    "from torch import Tensor\n",
    "\n",
    "import libs.hij_tensor as pt\n",
    "import libs.py_fock as fock\n",
    "import libs.py_integral as integral\n",
    "\n",
    "from vmc.PublicFunction import unit8_to_bit, check_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_lst(sorb: int, string: str):\n",
    "    arr = np.array(list(map(int, string)))[::-1]\n",
    "    lst = [0] * ((sorb-1)//64 +1)*8\n",
    "    for i in range((sorb-1)//8+1):\n",
    "        begin = i * 8\n",
    "        end = (i+1) * 8 if (i+1)*8 < sorb else sorb\n",
    "        idx = arr[begin:end]\n",
    "        lst[i] = np.sum(2**np.arange(len(idx)) * idx)\n",
    "\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "integral::load fname = integral/rmole-N2.info\n",
      "sorb = 20\n",
      "size(int1e) = 400:0.00305176MB:2.98023e-06GB\n",
      "size(int2e) = 18335:0.139885MB:0.000136606GB\n",
      "----- TIMING FOR integral::load_integral : 5.000e-03 S -----\n",
      "torch.Size([14400, 8])\n"
     ]
    }
   ],
   "source": [
    "chain_len = 10\n",
    "integral_file = f\"integral/rmole-N2.info\"\n",
    "int2e, int1e, ecore = integral.load(integral.two_body(), integral.one_body(), 0.0, integral_file)\n",
    "sorb = int2e.sorb\n",
    "# nele = chain_len\n",
    "nele = 14\n",
    "alpha_ele = 7 # nele//2 \n",
    "beta_ele = 7  # nele//2\n",
    "device = \"cuda\"\n",
    "space = fock.get_fci_space(int(sorb//2), alpha_ele, beta_ele)\n",
    "dim = len(space)\n",
    "\n",
    "# h1e/h2e \n",
    "h1e = torch.tensor(int1e.data, dtype=torch.float64).to(device)\n",
    "h2e = torch.tensor(int2e.data, dtype=torch.float64).to(device)\n",
    "\n",
    "# bra/ket\n",
    "lst = []\n",
    "for i in range(dim):\n",
    "    lst.append(string_to_lst(sorb, space[i].to_string()))\n",
    "onstate1 = torch.tensor(lst, dtype=torch.uint8).to(device)\n",
    "# onstate2 = torch.tensor(lst, dtype=torch.uint8).to(device)\n",
    "print(onstate1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[255,  63,   0,   0,   0,   0,   0,   0],\n",
      "        [255, 159,   0,   0,   0,   0,   0,   0],\n",
      "        [255, 183,   0,   0,   0,   0,   0,   0]], device='cuda:0',\n",
      "       dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(onstate1[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  where using detach()???从计算图脱离出来，不计算梯度\n",
    "def local_energy(x: Tensor, h1e: Tensor, h2e: Tensor, ansatz, sorb: int, nele: int,) ->tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Calculate the local energy for given state.\n",
    "    E_loc(x) = \\sum_x' psi(x')/psi(x) * <x|H|x'> \n",
    "    1. the all Signles and Doubles excitions about given state using cpu:\n",
    "        x: (1, sorb)/(batch, sorb) -> comb_x: (batch, ncomb, sorb)/(ncomb, sorb)\n",
    "    2. matrix <x|H|x'> (1, ncomb)/(batch, ncomb)\n",
    "    3. psi(x), psi(comb_x)[ncomb] using NAQS. \n",
    "    4. calculate the local energy\n",
    "    \"\"\"\n",
    "    check_para(x)\n",
    "    # TODO: \"get_comb_tensor\" in cuda \n",
    "    # TODO: python version x->comb_x\n",
    "\n",
    "    device = x.device\n",
    "    dim: int   = x.dim()\n",
    "    batch: int = x.shape[0]\n",
    "    t0 = time.time_ns()\n",
    "    comb_x = pt.get_comb_tensor(x.to(\"cpu\"), sorb, nele, True).to(device)\n",
    "    # calculate matrix <x|H|x'>\n",
    "    print(f\"comb_x delta t0: {(time.time_ns()-t0)/1.0E06:.3f} ms\")\n",
    "    comb_hij = pt.get_hij_torch(x, comb_x, h1e, h2e, sorb, nele) # shape (1, n)/(batch, n)\n",
    "    t1 =  time.time_ns()\n",
    "    # TODO: time consuming\n",
    "    x =  pt.unit8_to_bit(comb_x, sorb)\n",
    "    print(f\"unit8_to_bit t1: {(time.time_ns()-t1)/1.0E06:.3f} ms\")\n",
    "\n",
    "    t2 = time.time_ns()\n",
    "    psi_x1 = ansatz(x)\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\"ansatz delta t2: {(time.time_ns()-t2)/1.0E06:.3f} ms\")\n",
    "    # print(rbm.phase(unit8_to_bit(comb_x, sorb))[1])\n",
    "    # print(rbm.amplitude(unit8_to_bit(comb_x, sorb))[1])\n",
    "    if dim == 2 and batch == 1:\n",
    "        eloc  = torch.sum(comb_hij * psi_x1 / psi_x1[..., 0]) # scalar\n",
    "    elif dim == 2 and batch > 1:\n",
    "        eloc = torch.sum(torch.div(psi_x1.T, psi_x1[..., 0]).T * comb_hij, -1) # (batch)\n",
    "\n",
    "    return eloc, psi_x1[..., 0]\n",
    "\n",
    "# print(local_energy(onstate1[idx].view(1, -1), h1e, h2e, ansatz, sorb, nele)[0])\n",
    "# t0 = time.time_ns()\n",
    "# local_energy(onstate1, h1e, h2e, ansatz, sorb, nele)\n",
    "# delta = time.time_ns() - t0 \n",
    "# print(f\"Cost time: {delta/1.0E06:.3f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14400, 8])\n",
      "comb_x delta t0: 51.351 ms\n",
      "ket dim: unit8_to_bit t1: 70.953 ms\n",
      "3\n",
      "GPU Hmat initialization time: 0.280032 ms\n",
      "GPU calculate <n|H|m> time: 1.4145 ms\n",
      "Total function GPU function time: 1.74099 ms\n",
      "\n",
      "GPU calculate comb(unit8->bit) time: 65.83ms\n",
      "\n",
      "ansatz delta t2: 276.543 ms\n",
      "comb_x delta t0: 38.927 ms\n",
      "ket dim: 3\n",
      "GPU Hmat initialization time: 0.251968 ms\n",
      "GPU calculate <n|H|m> time: 1.28246 ms\n",
      "Total function GPU function time: 1.56877 ms\n",
      "\n",
      "GPU calculate comb(unit8->bit) time: 63.6314ms\n",
      "\n",
      "unit8_to_bit t1: 68.006 ms\n",
      "ansatz delta t2: 219.972 ms\n",
      "comb_x delta t0: 34.512 ms\n",
      "ket dim: 3\n",
      "GPU Hmat initialization time: 0.282048 ms\n",
      "GPU calculate <n|H|m> time: 1.14563 ms\n",
      "Total function GPU function time: 1.48429 ms\n",
      "\n",
      "GPU calculate comb(unit8->bit) time: 55.7564ms\n",
      "\n",
      "unit8_to_bit t1: 59.668 ms\n",
      "ansatz delta t2: 175.141 ms\n",
      "tensor(-106.0730, device='cuda:0', dtype=torch.float64)\n",
      "Cost time: 1004.012 ms\n"
     ]
    }
   ],
   "source": [
    "def total_enrgy(x: Tensor, nbatch: int, h1e: Tensor, h2e: Tensor, ansatz, \n",
    "                sorb: int, nele: int, device: str=\"cuda\"):\n",
    "    dim: int = x.shape[0]\n",
    "    eloc_lst = torch.zeros(dim, dtype=torch.float64).to(device)\n",
    "    psi_lst = torch.zeros(dim, dtype=torch.float64).to(device)\n",
    "    idx_lst = torch.arange(dim).to(device)\n",
    "\n",
    "    # calculate the total energy using splits\n",
    "    for ons, idx in zip(x.split(nbatch), idx_lst.split(nbatch)):\n",
    "        eloc_lst[idx], psi_lst[idx] =  local_energy(ons, h1e, h2e, ansatz, sorb, nele)\n",
    "    \n",
    "    return (eloc_lst * (psi_lst.pow(2)/(psi_lst.pow(2).sum()))).sum()\n",
    "\n",
    "from vmc.ansatz import RBM \n",
    "rbm = RBM(sorb, sorb*2)\n",
    "ansatz = rbm.prob\n",
    "\n",
    "t0 = time.time_ns()\n",
    "print(onstate1.shape)\n",
    "e = total_enrgy(onstate1, 5000, h1e, h2e, ansatz, sorb, nele)\n",
    "torch.cuda.synchronize()\n",
    "delta = time.time_ns() - t0 \n",
    "print(e)\n",
    "print(f\"Cost time: {delta/1.0E06:.3f} ms\")\n",
    "\n",
    "# H10\n",
    "# tensor(-11.0171, device='cuda:0', dtype=torch.float64)\n",
    "# GPU 3568Mb\n",
    "# Cost time: 6361.739 ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c763cec028a98f3e988162684808c3005c60a7dccfebd0b415fd12b14c9f0b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
